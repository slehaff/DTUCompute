{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_by_manual_registration(source,target,\n",
    "                            \n",
    "                             threshold = 0.03,\n",
    "                             picked_id_source = None,\n",
    "                             picked_id_target = None,\n",
    "                                      \n",
    "                             #statements\n",
    "                             print_statements = False,\n",
    "                             visualization_on = False\n",
    "                             ):\n",
    "    \"\"\"\n",
    "    transf,picked_id_source,picked_id_target = evaluation_by_manual_registration\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    if picked_id_source is None: \n",
    "        # pick points from two point clouds and builds correspondences\n",
    "        picked_id_source = pick_points(source)\n",
    "        \n",
    "    if picked_id_target is None:\n",
    "        picked_id_target = pick_points(target)\n",
    "    \n",
    "    print (picked_id_source)\n",
    "    assert (len(picked_id_source) >= 3 and len(picked_id_target) >= 3)\n",
    "    assert (len(picked_id_source) == len(picked_id_target))\n",
    "    corr = np.zeros((len(picked_id_source), 2))\n",
    "    corr[:, 0] = picked_id_source\n",
    "    corr[:, 1] = picked_id_target\n",
    "\n",
    "    # estimate rough transformation using correspondences\n",
    "    if print_statements == True:\n",
    "        print(\"Compute a rough transform using the correspondences given by user\")\n",
    "    p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    trans_init = p2p.compute_transformation(source, target,\n",
    "                                            o3d.utility.Vector2iVector(corr))\n",
    "\n",
    "    # point-to-point ICP for refinement\n",
    "    if print_statements == True:\n",
    "        print(\"Perform point-to-point ICP refinement\")\n",
    "    threshold = threshold  # 3cm distance threshold\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    transf = reg_p2p.transformation \n",
    "    \n",
    "    print (reg_p2p)\n",
    "    if visualization_on == True: \n",
    "        draw_registration_result(source, target, transf)\n",
    "        \n",
    "    if print_statements == True:\n",
    "        print(\"\")\n",
    "        print (reg_p2p)\n",
    "        print(transf) \n",
    "    return transf,picked_id_source,picked_id_target,reg_p2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_evaluation_pipeline(\n",
    "                             #input \n",
    "                             list_stitches,\n",
    "                             labels_stitches = [\"model_pc\",\"stitched_pc\"],\n",
    "                             color_stitches = [[1, 0.706, 0],[0, 0.651, 0.929]],\n",
    "                             \n",
    "                             #plotting \n",
    "                             params = myparams,  # parameter for camera point view, json file via pressing P\n",
    "                             configuration_file = myconfiguration_file, # configuration file for properties, json file via pressing o\n",
    "                             take_screen_shot = True,\n",
    "                             rotate = False,\n",
    "                             onewindow = True,\n",
    "                             \n",
    "                             #scaling\n",
    "                             scale_factor = 1000,\n",
    "                             voxels = [0.1,0.2],\n",
    "                             \n",
    "                             #evaluation \n",
    "                             threshold = 0.03,\n",
    "                             picked_id_source = None,\n",
    "                             picked_id_target = None,\n",
    "    \n",
    "                             #statements\n",
    "                             print_statements = False,\n",
    "                             visualization_on = False\n",
    "                            ):\n",
    "    \"\"\"\n",
    "    list_stitches = [pcd,st_pcd]\n",
    "        pcd = original point cloud of the model\n",
    "        st_pcd = our stitched point cloud that we want to evaluate against the model \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # check input size\n",
    "    assert len(list_stitches) == len(labels_stitches) \n",
    "    assert len(labels_stitches) == len(color_stitches)\n",
    "    assert len(color_stitches) == 2\n",
    "    \n",
    "    #\n",
    "    pcd,st_pcd = list_stitches\n",
    "\n",
    "    ## assign colors\n",
    "    list_stitches[0].paint_uniform_color(color_stitches[0])\n",
    "    list_stitches[1].paint_uniform_color(color_stitches[1])\n",
    "    \n",
    "    # mytitle\n",
    "    mytitle = f\"{labels_stitches[0]}_{get_color_name(color_stitches[0])}-{labels_stitches[1]}_{get_color_name(color_stitches[1])}\"\n",
    "    \n",
    "    \n",
    "    if visualization_on == True:\n",
    "        # plot a list of geometries\n",
    "        custom_draw_geometry(list_stitches[0]+list_stitches[1],\n",
    "                             mytitle = mytitle+\"before_resizing\",\n",
    "                             params = params,  # parameter for camera point view, json file via pressing P\n",
    "                             configuration_file = configuration_file, # configuration file for properties, json file via pressing o\n",
    "                             take_screen_shot = take_screen_shot,\n",
    "                             rotate = rotate,\n",
    "                             onewindow = onewindow)\n",
    "    \n",
    "    #define scaling function \n",
    "    trans_scale = np.asarray([[scale_factor, 0.0, 0.0, 0.0], \n",
    "                             [0.0, scale_factor, 0.0, 0.0],\n",
    "                             [0.0, 0.0, scale_factor, 0.0], \n",
    "                             [0.0, 0.0, 0.0, 1.0]])\n",
    "    \n",
    "    # apply scaling function\n",
    "    temp_pcd = copy.deepcopy(pcd)\n",
    "    temp_pcd.transform(trans_scale)\n",
    "    list_stitches[0] = temp_pcd\n",
    "    \n",
    "    if visualization_on == True:\n",
    "        # plot a list of geometries\n",
    "        custom_draw_geometry(list_stitches[0]+list_stitches[1],\n",
    "                             mytitle = mytitle+\"after_resizing\",\n",
    "                             params = params,  # parameter for camera point view, json file via pressing P\n",
    "                             configuration_file = configuration_file, # configuration file for properties, json file via pressing o\n",
    "                             take_screen_shot = take_screen_shot,\n",
    "                             rotate = rotate,\n",
    "                             onewindow = onewindow)\n",
    "        \n",
    "    #downsampling\n",
    "    down_pcd = temp_pcd.voxel_down_sample(voxel_size=voxels[0])\n",
    "    down_st_pcd = st_pcd.voxel_down_sample(voxel_size=voxels[1])\n",
    "    downsampled_stitches = [down_pcd,down_st_pcd]\n",
    "    \n",
    "    if print_statements == True:\n",
    "        print (len(down_pcd.points))\n",
    "        print (len(down_st_pcd.points))\n",
    "        \n",
    "    #set source and target\n",
    "    source = copy.deepcopy(downsampled_stitches[0])\n",
    "    target = copy.deepcopy(downsampled_stitches[1])\n",
    "    \n",
    "    # evaluation by manual icp registration \n",
    "    transf,new_picked_id_source,new_picked_id_target, registration = evaluation_by_manual_registration(source,target,\n",
    "                                                                             threshold = 0.03,\n",
    "                                                                             picked_id_source = picked_id_source,\n",
    "                                                                             picked_id_target = picked_id_target,\n",
    "                                                                             visualization_on = visualization_on\n",
    "                                                                            )\n",
    "    \n",
    "    return transf,new_picked_id_source,new_picked_id_target,registration,list_stitches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
