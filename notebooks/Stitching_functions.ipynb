{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd_down, voxel_size,pprint_statements = False):\n",
    "    \n",
    "    #pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    radius_normal = voxel_size * 2\n",
    "    radius_feature = voxel_size * 5\n",
    "    \n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=230))\n",
    "    \n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=230))\n",
    "    \n",
    "    if pprint_statements== True: \n",
    "        print(\"\\n Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "        print(\"Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "        print(\"Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "\n",
    "def prepare_dataset(source,target,voxel_size, trans_init = None,mytitle = \"\", print_statements = False):\n",
    "    \"\"\"\n",
    "    source and target are already downsampled \n",
    "    \"\"\"\n",
    "    \n",
    "    #if print_statements== True:\n",
    "        #print(\"Load two point clouds and disturb initial pose.\")\n",
    "    #trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             # [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    \n",
    "    # TO DO check what happens with/without this\n",
    "    #source.transform(trans_init)\n",
    "    # draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "\n",
    "    \n",
    "    #outlier removal\n",
    "    if print_statements== True:\n",
    "        print (\"removing outliers\")\n",
    "    processed_source, outlier_index = source.remove_radius_outlier(\n",
    "                                              nb_points=25,\n",
    "                                              radius=0.5)\n",
    "\n",
    "    processed_target, outlier_index = target.remove_radius_outlier(\n",
    "                                              nb_points=25,\n",
    "                                              radius=0.5)\n",
    "\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh, trans_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## global and icp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size,\n",
    "                                max_iteration,\n",
    "                                max_validation,\n",
    "                                print_statements = False,\n",
    "                               ):\n",
    "    distance_threshold = voxel_size *1.5\n",
    "    \n",
    "    if print_statements== True: \n",
    "        print(\"\\nGLOBAL REGISTRATION: RANSAC registration on downsampled point clouds.\")\n",
    "        #print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "        #print(\"   we use a liberal distaÂ¢nce threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.99),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(max_iteration,max_validation))\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#icp\n",
    "def refine_registration(source, target, \n",
    "                        source_fpfh, target_fpfh, \n",
    "                        voxel_size,\n",
    "                        mytranformation = None,\n",
    "                        print_statements = False\n",
    "                       ):\n",
    "    \n",
    "    distance_threshold = voxel_size *2\n",
    "    \n",
    "    if print_statements== True: \n",
    "        print(\"\\nPOINT-TO-PLANE ICP registration is applied on original point\")\n",
    "        print(\"distance threshold %.3f.\" % distance_threshold)\n",
    "        \n",
    "    #if type(mytranformation) != \"numpy.ndarray\":\n",
    "        #mytranformation = np.identity(4)\n",
    "        \n",
    "    \n",
    "    radius_normal = voxel_size * 5\n",
    "    \n",
    "    source.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=230))\n",
    "    target.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=230))\n",
    "    \n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, mytranformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_points(list_pointclouds, print_statement = False):\n",
    "    num_points = []\n",
    "    n_pc = list(range(len(list_pointclouds)))\n",
    "    for i in n_pc:\n",
    "        points = len(np.asarray(list_pointclouds[i].points))\n",
    "        num_points.append(points)\n",
    "    print(\"\")\n",
    "    if print_statement == True:\n",
    "        print(\"\")\n",
    "        print(\"number of points in clouds\")\n",
    "        print (*zip(n_pc,num_points), sep = \"\\n\")\n",
    "    return num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_registration_result(source, target, transformation,\n",
    "                             \n",
    "                             #visualization parameters\n",
    "                             title = \"\", mytuples = None, \n",
    "                             params = None, #camera parameters,json file (P)\n",
    "                             fov_step  = None, \n",
    "                             configuration_file = None, #object properties ,json file (O)\n",
    "                             rotate = False,\n",
    "                             \n",
    "                             save_result = True,\n",
    "                             visualize_result = False):\n",
    "    \n",
    "    filename = dt_string+'-stitch_'+title+'.pcd'\n",
    "    \n",
    "    # apply the chosen transformation to source and target\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    \n",
    "    # combine them and create the newpoint cloud\n",
    "    newpointcloud = source_temp + target_temp\n",
    "    newpointcloud.paint_uniform_color([0,0.5,0.1])\n",
    "    \n",
    "    #save\n",
    "    if save_result == True: \n",
    "        o3d.io.write_point_cloud(filename, newpointcloud)\n",
    "    \n",
    "    #visualize\n",
    "    if visualize_result == True:\n",
    "        #o3d.visualization.draw_geometries([newpointcloud],\n",
    "                                         # width=1000, height=800,\n",
    "                                         #window_name=title)\n",
    "        \n",
    "        \n",
    "        custom_draw_geometry(newpointcloud,\n",
    "                     mytitle = title,\n",
    "                     params = params,  # parameter for camera point view, json file via pressing P\n",
    "                     configuration_file = configuration_file, # configuration file for properties, json file via pressing o\n",
    "                     rotate = rotate\n",
    "                            )\n",
    "        \n",
    "        \n",
    "        \n",
    "    return newpointcloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_two_point_clouds(source, target, \n",
    "                            mytitle,dt_string, \n",
    "                            voxel_size,\n",
    "                            calculate_global = True,\n",
    "                            calculate_icp = True, # mark False if you want to skip this step\n",
    "                            trans_init = None,\n",
    "                            pprint_statements = False,\n",
    "                            save_statements = True,\n",
    "                            visualization_on = False,\n",
    "                            final_vis_on = True,\n",
    "                            mmax_iteration = 10**7,\n",
    "                            mmax_validation = 0.999,\n",
    "                            myoverlapping_factor = 0.7,\n",
    "                            maxnumattempts = 100):\n",
    "    #list of transformations\n",
    "    trasformations_list = []\n",
    "    \n",
    "    # print \n",
    "    print (\"stitching : %s\" %mytitle)\n",
    "    \n",
    "    # Use different colors on the two point clouds\n",
    "    source.paint_uniform_color([1, 0.706, 0])    #source is yellow\n",
    "    target.paint_uniform_color([0, 0.651, 0.929])#target is blue\n",
    "    \n",
    "    # visualize\n",
    "    geometry_list = [source,target]\n",
    "    if visualization_on == True:\n",
    "        o3d.visualization.draw_geometries(geometry_list,\n",
    "                                          width=1000, height=800,\n",
    "                                          window_name='Open3D-original %s'%mytitle)\n",
    "        \n",
    "    #Outlier removal for two point clouds separately\n",
    "    if pprint_statements == True:\n",
    "        print (\"\\noutlier removal\")\n",
    "    processed_source, outlier_index_source = source.remove_radius_outlier(\n",
    "                                                  nb_points=16,\n",
    "                                                  radius=0.45)\n",
    "\n",
    "    processed_target, outlier_index_target = target.remove_radius_outlier(\n",
    "                                                  nb_points=16,\n",
    "                                                  radius=0.5)\n",
    "    \n",
    "    if visualization_on == True:\n",
    "        o3d.visualization.draw_geometries([processed_source,processed_target],\n",
    "                                          width=1000, height=800,\n",
    "                                          window_name='Open3D-processed %s'%mytitle)\n",
    "\n",
    "\n",
    "    # note: here we are re-defining the source and target as processed\n",
    "    if pprint_statements == True:\n",
    "        print (\"\\ndataset preparation\")\n",
    "    source, target, source_down, target_down, source_fpfh, target_fpfh,trans_init = prepare_dataset(processed_source,\n",
    "                                                                                             processed_target,\n",
    "                                                                                             voxel_size, \n",
    "                                                                                             trans_init,\n",
    "                                                                                             mytitle =mytitle,\n",
    "                                                                                             print_statements = pprint_statements\n",
    "                                                                                              )\n",
    "    # append the just obtained one as trasformations_list\n",
    "    trasformations_list.append(trans_init)\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    #being in sequence the overlapping in a proper stitching should be high\n",
    "    #Therefore we put a condition:\n",
    "    #> while result_icp.correspondence_set < 0.7*(len(np.asarray(source.points))+len(np.asarray(target.points)))\n",
    "    #> do execute_global_registration\n",
    "    \n",
    "    #points_source = len(np.asarray(source.points))\n",
    "    #points_target = len(np.asarray(target.points))\n",
    "    \n",
    "    points_source,points_target = get_num_points([source,target],print_statement = pprint_statements)\n",
    "    overlapping_points = np.zeros(1) # initialization \n",
    "    numattempts = 0\n",
    "    \n",
    "    while (numattempts <= maxnumattempts) and (len(np.asarray(overlapping_points)) < myoverlapping_factor*(points_target)):\n",
    "    #-----------------------------------------------------------------------------------------------------    \n",
    "        # ok in reality we always want to calculate the global ... or? \n",
    "        if calculate_global== True: \n",
    "            #global registration: execute ransac\n",
    "            result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                                        source_fpfh, target_fpfh,\n",
    "                                                        voxel_size,\n",
    "                                                        max_iteration = mmax_iteration,\n",
    "                                                        max_validation = mmax_validation,\n",
    "                                                        print_statements = pprint_statements\n",
    "                                                       )\n",
    "            #print result\n",
    "            if pprint_statements == True:\n",
    "                print(\"Fit is:\")\n",
    "                print (type(result_ransac))\n",
    "                print(result_ransac)\n",
    "                print(\"Transformation is:\")\n",
    "                print(result_ransac.transformation)\n",
    "\n",
    "            #save it\n",
    "            if save_statements == True: \n",
    "                with open(dt_string+'-transformation_result_ransac-'+mytitle+'.pkl','wb') as f:\n",
    "                    pkl.dump(result_ransac.transformation, f)\n",
    "                if pprint_statements == True:\n",
    "                    print(\"saved\")\n",
    "\n",
    "            threshold = 0.01\n",
    "\n",
    "            if visualization_on == True: \n",
    "                draw_registration_result(source, target, \n",
    "                                         result_ransac.transformation,\n",
    "                                         title = \"global registration-%s\"%mytitle,\n",
    "                                        )\n",
    "\n",
    "            # append the just obtained one as trasformations_list\n",
    "            trasformations_list.append(result_ransac.transformation)\n",
    "\n",
    "            points_source,points_target = get_num_points([source,target],print_statement = pprint_statements)\n",
    "            overlapping_points = result_ransac.correspondence_set\n",
    "            if pprint_statements == True:\n",
    "                print (\"overlapping points : \" ,len(np.asarray(overlapping_points)))\n",
    "                \n",
    "            numattempts += 1\n",
    "        #-----------------------------------------------------------------------------------------------------\n",
    "        if calculate_icp== True: \n",
    "            #execute icp\n",
    "            result_icp = refine_registration(source, target, \n",
    "                                             source_fpfh, target_fpfh,\n",
    "                                             voxel_size,\n",
    "                                             mytranformation =trasformations_list[-1],\n",
    "                                             print_statements = pprint_statements\n",
    "                                            )\n",
    "            # print result\n",
    "            if pprint_statements == True:\n",
    "                print(\"Fit is:\")\n",
    "                print(result_icp)\n",
    "                print(\"Transformation is:\")\n",
    "                print(result_icp.transformation)\n",
    "            #save it\n",
    "            if save_statements == True: \n",
    "                with open(dt_string+'-transformation_result_icp-'+mytitle+'.pkl','wb') as f:\n",
    "                    pkl.dump(result_icp.transformation, f)\n",
    "                if pprint_statements == True:\n",
    "                    print(\"saved\")\n",
    "\n",
    "            #append the just obtained one as trasformations_list\n",
    "            trasformations_list.append(result_icp.transformation)\n",
    "\n",
    "\n",
    "            points_source,points_target = get_num_points([source,target],print_statement = pprint_statements)\n",
    "            overlapping_points = result_icp.correspondence_set\n",
    "            if pprint_statements == True:\n",
    "                print (\"overlapping points : \" ,len(np.asarray(overlapping_points)))\n",
    "\n",
    "        numattempts += 1\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    if final_vis_on == True: \n",
    "        draw_registration_result(source, target, \n",
    "                                 trasformations_list[-1],\n",
    "                                 title = \"last fit registration-%s\"%mytitle\n",
    "                                )\n",
    "        \n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #save it\n",
    "    newpointcloud = save_registration_result(source, target, trasformations_list[-1], \n",
    "                                             mytitle, \n",
    "                                             save_result = save_statements,\n",
    "                                             visualize_result = False)\n",
    "    \n",
    "    return newpointcloud,trasformations_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_sequences(processed_source,processed_target,\n",
    "                     source_label,target_label,\n",
    "                     mmax_iteration = 10**7,\n",
    "                     mmax_validation = 0.999,\n",
    "                     print_statements = False,\n",
    "                     visualization_on = False\n",
    "                     ):\n",
    "    mytitle = \"allpc_downsampled_%s_%s\" %(source_label,target_label)\n",
    "    print(mytitle)\n",
    "\n",
    "\n",
    "    # prepare dataset\n",
    "    new_source, new_target, source_down, target_down, source_fpfh, target_fpfh,trans_init = prepare_dataset(processed_source,\n",
    "                                                                                                 processed_target,\n",
    "                                                                                                 voxel_size=voxel_size, \n",
    "                                                                                                 #trans_init,\n",
    "                                                                                                 mytitle =mytitle,\n",
    "                                                                                                 print_statements = print_statements\n",
    "                                                                                         )\n",
    "\n",
    "    # plot\n",
    "    if  visualization_on == True: \n",
    "        custom_draw_geometry((processed_target+processed_source),\n",
    "                         mytitle = mytitle,\n",
    "                         params = myparams,  # parameter for camera point view, json file via pressing P\n",
    "                         configuration_file = myconfiguration_file, # configuration file for properties, json file via pressing o\n",
    "                         rotate = True)\n",
    "    \n",
    "\n",
    "\n",
    "    # GLOBAL \n",
    "    result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                                source_fpfh, target_fpfh,\n",
    "                                                voxel_size= voxel_size,\n",
    "                                                print_statements = print_statements,\n",
    "                                                max_iteration = mmax_iteration,\n",
    "                                                max_validation = mmax_validation \n",
    "                                               )\n",
    "    \n",
    "    overlapping_points = result_ransac.correspondence_set\n",
    "    \n",
    "    if print_statements == True :\n",
    "        print(\"Transformation is:\")\n",
    "        print(result_ransac.transformation)\n",
    "        print (\"overlapping points : \" ,len(np.asarray(overlapping_points)))\n",
    "        print (result_ransac)\n",
    "\n",
    "    #plot\n",
    "    if visualization_on == True :\n",
    "        draw_registration_result(new_source, new_target, \n",
    "                             result_ransac.transformation,\n",
    "                             title = \"%global registration\"\n",
    "                            )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ICP\n",
    "    result_icp = refine_registration(new_source, new_target, \n",
    "                                                 source_fpfh, target_fpfh,\n",
    "                                                 voxel_size,\n",
    "                                                 mytranformation =result_ransac.transformation,\n",
    "                                                 print_statements = print_statements\n",
    "                                                )\n",
    "\n",
    "    overlapping_points = result_icp.correspondence_set\n",
    "    \n",
    "    \n",
    "    if print_statements == True :\n",
    "        print(\"Transformation is:\")\n",
    "        print(result_icp.transformation)\n",
    "        print (\"overlapping points : \" ,len(np.asarray(overlapping_points)))\n",
    "        print (result_icp)\n",
    "\n",
    "    if visualization_on == True :\n",
    "        draw_registration_result(new_source, new_target, \n",
    "                                 result_icp.transformation,\n",
    "                                 title = \"icp registration\"\n",
    "                                 )\n",
    "        \n",
    "    \n",
    "    return new_source, new_target, result_icp.transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_by_manual_registration(source,target,\n",
    "                            \n",
    "                             threshold = 0.03,\n",
    "                             picked_id_source = None,\n",
    "                             picked_id_target = None\n",
    "                             ):\n",
    "    \"\"\"\n",
    "    transf,picked_id_source,picked_id_target = evaluation_by_manual_registration\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    if picked_id_source is None: \n",
    "        # pick points from two point clouds and builds correspondences\n",
    "        picked_id_source = pick_points(source)\n",
    "        \n",
    "    if picked_id_target is None:\n",
    "        picked_id_target = pick_points(target)\n",
    "    \n",
    "    print (picked_id_source)\n",
    "    assert (len(picked_id_source) >= 3 and len(picked_id_target) >= 3)\n",
    "    assert (len(picked_id_source) == len(picked_id_target))\n",
    "    corr = np.zeros((len(picked_id_source), 2))\n",
    "    corr[:, 0] = picked_id_source\n",
    "    corr[:, 1] = picked_id_target\n",
    "\n",
    "    # estimate rough transformation using correspondences\n",
    "    print(\"Compute a rough transform using the correspondences given by user\")\n",
    "    p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    trans_init = p2p.compute_transformation(source, target,\n",
    "                                            o3d.utility.Vector2iVector(corr))\n",
    "\n",
    "    # point-to-point ICP for refinement\n",
    "    print(\"Perform point-to-point ICP refinement\")\n",
    "    threshold = threshold  # 3cm distance threshold\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    \n",
    "    draw_registration_result(source, target, reg_p2p.transformation)\n",
    "    print(\"\")\n",
    "    transf = reg_p2p.transformation \n",
    "    return transf,picked_id_source,picked_id_target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
